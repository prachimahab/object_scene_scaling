{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import scipy \n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def combineCSVs(datafolder):\n",
    "    \"\"\"\n",
    "    Combine all participant data into one pandas df\n",
    "    OR \n",
    "    Create df for single participant file \n",
    "    \"\"\"\n",
    "    \n",
    "    exclude = []\n",
    "    \n",
    "    #checks if path is a file \n",
    "    isFile = os.path.isfile(datafolder)\n",
    "    print(isFile)\n",
    "\n",
    "    #checks if path is a directory\n",
    "    \n",
    "    isDirectory = os.path.isdir(datafolder)\n",
    "    \n",
    "    if isDirectory == True:\n",
    "        data = []\n",
    "        for filename in os.listdir(datafolder):\n",
    "            if 'csv' in filename:\n",
    "                path = datafolder + \"/\" + filename\n",
    "                df = pd.read_csv(path, index_col=None, header=0)\n",
    "                \n",
    "                # do NOT include subject IDs that have been flagged \n",
    "                subjID = df.subjID.unique()[0]\n",
    "                if subjID not in exclude:\n",
    "                    data.append(df)\n",
    "\n",
    "                \n",
    "        input_frame = pd.concat(data, axis=0, ignore_index=True)\n",
    "        \n",
    "    if isFile == True:\n",
    "        if 'csv' in datafolder:\n",
    "            input_frame = pd.read_csv(datafolder, index_col=None, header=0)\n",
    "    \n",
    " \n",
    "    return input_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/pmahableshwarkar/Documents/object_scene_scaling/v6_b1_data.csv'\n",
    "# data_path = '/Users/prachimahableshwarkar/Documents/GW/OSS/v6_b1_data.csv'\n",
    "# data_path = '/Users/prachimahableshwarkar/Documents/GW/FacialAge/FacialAge_MTurk/OSS_MTurk/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "df = combineCSVs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subjID', 'experimentName', 'versionName', 'windowWidth',\n",
       "       'windowHeight', 'screenWidth', 'screenHeight', 'startDate', 'startTime',\n",
       "       'pracTries', 'trialNum', 'objectSize', 'objectCategory', 'object',\n",
       "       'misscaled', 'objectScene1SemanticCongruency', 'scene1ZoomName',\n",
       "       'scene1Category', 'scene1', 'scene2SizeCong', 'scene2SemCong',\n",
       "       'scene2ZoomName', 'scene2Category', 'scene2', 'keyPress', 'accuracy',\n",
       "       'RT', 'experimentTime', 'totalTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "\n",
    "# misscaled, objectScene1SemanticCongruency, scene1ZoomName, scene2SizeCong, scene2SemCong, scene2ZoomName, accuracy, RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 336)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misscaled = np.array(df['misscaled'])\n",
    "objectScene1SemanticCongruency = np.array(df['objectScene1SemanticCongruency'])\n",
    "scene1ZoomName = np.array(df['scene1ZoomName'])\n",
    "scene2SizeCong = np.array(df['scene2SizeCong'])\n",
    "scene2SemCong = np.array(df['scene2SemCong'])\n",
    "scene2ZoomName = np.array(df['scene2ZoomName'])\n",
    "accuracy = np.array(df['accuracy'])\n",
    "RT = np.array(df['RT'])\n",
    "\n",
    "len(misscaled), len(RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data = [misscaled, objectScene1SemanticCongruency, scene1ZoomName, scene2SizeCong, scene2SemCong, scene2ZoomName, accuracy, RT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take random subset of data for a range of fractions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lists_to_df(data, cols):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        df[cols[i]] = data[i]\n",
    "    \n",
    "    print(len(df))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "134\n",
      "201\n",
      "268\n",
      "336\n"
     ]
    }
   ],
   "source": [
    "frac = [0.2, 0.4, 0.6, 0.8, 1]\n",
    "\n",
    "all_frac_dfs = []\n",
    "for i in range(len(frac)):\n",
    "    # Shuffle two lists with same order\n",
    "    # Using zip() + * operator + shuffle()\n",
    "    temp = list(zip(misscaled, objectScene1SemanticCongruency, scene1ZoomName, scene2SizeCong, scene2SemCong, scene2ZoomName, accuracy, RT))\n",
    "    random.shuffle(temp)\n",
    "\n",
    "    s_misscaled, s_objectScene1SemanticCongruency, s_scene1ZoomName, s_scene2SizeCong, s_scene2SemCong, s_scene2ZoomName, s_accuracy, s_RT = zip(*temp)\n",
    "\n",
    "    # res1 and res2 come out as tuples, and so must be converted to lists.\n",
    "    s_misscaled, s_objectScene1SemanticCongruency, s_scene1ZoomName, s_scene2SizeCong, s_scene2SemCong, s_scene2ZoomName, s_accuracy, s_RT = list(s_misscaled), list(s_objectScene1SemanticCongruency), list(s_scene1ZoomName), list(s_scene2SizeCong), list(s_scene2SemCong), list(s_scene2ZoomName), list(s_accuracy), list(s_RT)\n",
    "    \n",
    "    data = [s_misscaled, s_objectScene1SemanticCongruency, s_scene1ZoomName, s_scene2SizeCong, s_scene2SemCong, s_scene2ZoomName, s_accuracy, s_RT]\n",
    "    frac_data = []\n",
    "    for elem in data:\n",
    "        frac_elem = elem[:int(len(elem)*frac[i])]\n",
    "        frac_data.append(frac_elem)\n",
    "\n",
    "    cols = ['misscaled', 'objectScene1SemanticCongruency', 'scene1ZoomName', 'scene2SizeCong', 'scene2SemCong', 'scene2ZoomName', 'accuracy', 'RT']\n",
    "    frac_df = lists_to_df(frac_data, cols)\n",
    "    all_frac_dfs.append(frac_df)\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 403\n",
      "134 470\n",
      "201 537\n",
      "268 604\n",
      "336 672\n"
     ]
    }
   ],
   "source": [
    "for f in frac:\n",
    "    print(int(len(og_data[0]) * f), len(og_data[0]) + int(len(og_data[0]) * f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_df = pd.DataFrame()\n",
    "cols = ['misscaled', 'objectScene1SemanticCongruency', 'scene1ZoomName', 'scene2SizeCong', 'scene2SemCong', 'scene2ZoomName', 'accuracy', 'RT']\n",
    "    \n",
    "for i in range(len(og_data)):\n",
    "    og_df[cols[i]] = og_data[i]\n",
    "    \n",
    "# og_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add original data to the fraction of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(frac)):\n",
    "    frac_df = all_frac_dfs[i]\n",
    "    fraction = str(frac[i])\n",
    "    print(fraction)\n",
    "    new_df = pd.concat([og_df, frac_df])\n",
    "    new_df.to_csv('power_analysis/v6_b1_data_' + fraction + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
